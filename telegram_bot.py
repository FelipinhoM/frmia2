import os
import time
from telegram import Update
from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, filters, ContextTypes
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings
from langchain.chains import RetrievalQA
from langchain_community.chat_models import ChatOpenAI

# Vari√°veis de ambiente
openai_key = os.getenv("OPENAI_API_KEY")
telegram_token = os.getenv("TELEGRAM_TOKEN")

# Caminho do √≠ndice FAISS
INDEX_DIR = "/mnt/data/faiss_index"
INDEX_FILE = os.path.join(INDEX_DIR, "index.faiss")

# Esperar o √≠ndice vetorizado ser gerado
print("‚è≥ Aguardando a cria√ß√£o do √≠ndice vetorizado...")
while not os.path.exists(INDEX_FILE):
    time.sleep(2)

print("‚úÖ √çndice vetorizado encontrado!")

# Carregar base vetorizada
db = FAISS.load_local(INDEX_DIR, OpenAIEmbeddings(openai_api_key=openai_key), allow_dangerous_deserialization=True)
qa_chain = RetrievalQA.from_chain_type(
    llm=ChatOpenAI(temperature=0.1, openai_api_key=openai_key),
    retriever=db.as_retriever()
)

# Handlers do bot
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("Ol√°! Pode me perguntar qualquer coisa com base nos dados do formul√°rio.")

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    question = update.message.text
    result = qa_chain.run(question)

    # Resposta padr√£o se n√£o achar dados relevantes
    if "n√£o sei" in result.lower() or not result.strip():
        response = "Nenhum registro encontrado com base nessa pergunta. Talvez o campo n√£o tenha sido preenchido."
    else:
        response = result

    await update.message.reply_text(response)

# Iniciar o bot
if __name__ == "__main__":
    app = ApplicationBuilder().token(telegram_token).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    print("ü§ñ Bot est√° rodando...")
    app.run_polling()
